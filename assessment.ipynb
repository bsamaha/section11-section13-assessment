{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objectives\n",
    "YW\n",
    "* scrape a website for relevant information, store that information to a dataframe and save that dataframe as a csv file\n",
    "* load in a dataframe and do the following\n",
    "    * calculate the zscores of a given column\n",
    "    * calculate the zscores of a point from a given column in the dataframe\n",
    "    * calculate and plot the pmf and cdf of another column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Webscraping\n",
    "* use the following url scrape the first page of results\n",
    "* for each item get the name of the item\n",
    "* store the names to a dataframe and save that dataframe to csv then display\n",
    "    * store the dataframe in the `data` folder in the repo\n",
    "    * name the file `part1.csv` and make sure that when you write it you set `index=False`\n",
    "* the head of the dataframe\n",
    "\n",
    "* it should match the following\n",
    "<img src=\"solutions/images/part1.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.petsmart.com/dog/treats/dental-treats/#page_name=flyout&category=dog&cta=dentaltreat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape the data\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "web = requests.get(url)\n",
    "print(web.status_code) #make sure we can access the website\n",
    "src = web.content #see the content of the website\n",
    "soup = BeautifulSoup(src) #turn the content into a soup object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ran this code and examined the website using the google developer tab (F12) and also right clicking inspect on the desired info I want to scrape. All product names are under the heading.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "product_name_list = [] #establish a new empty list\n",
    "for product in soup.find_all('h3'): #iterate through the soup object to find all <h3> headings\n",
    "    product_name_list.append(product.get_text()) #return only the text from that <h3> heading\n",
    "                                                 #and put it in our empty list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-6557dae5f0c0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdf_raw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproduct_name_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'productNames'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#raw data df.. need to be examined\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m36\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m#everything good but needed to remove the last two items that were not products\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'part1.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m# save the data as a csv file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df_raw = pd.DataFrame(product_name_list, columns=['productNames']) #raw data df.. need to be examined\n",
    "df = df.iloc[:36] #everything good but needed to remove the last two items that were not products\n",
    "df.to_csv('part1.csv', index=False)# save the data as a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display df.head()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2\n",
    "\n",
    "load in the csv file located in the `data` folder called `part2.csv`\n",
    "\n",
    "create a function that calculates the zscores of an array\n",
    "\n",
    "then calculate the zscores for each column in part2.csv and add them as columns\n",
    "\n",
    "See below for final result\n",
    "\n",
    "<img src=\"solutions/images/part2_df_preview.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "part2 = pd.read_csv('./data/part2.csv')\n",
    "part2.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in part2: #iterate through the columns in the part 2 dataframe\n",
    "    part2[column + '_zscores'] = stats.zscore(part2[column])\n",
    "    #create a new column add _zscore to the column name and calculate the respective z_score\n",
    "part2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function that calculates the zscores of an array\n",
    "def get_zscore(data):\n",
    "    data = np.array(data) #just in case we accidentally call a list\n",
    "    mu = data.mean() #could also use data.sum() / len(data)\n",
    "    std = data.std()\n",
    "    z_lst = []\n",
    "    for point in data:\n",
    "        z = (point - mu) / std\n",
    "        z_lst.append(z)\n",
    "    z_lst = np.array(z_lst)\n",
    "    return z_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the zscore for each column and store them as a new column with the names used above\n",
    "part2['eventOutcome_test_myzfunc'] = get_zscore(part2['eventOutcome'])\n",
    "\n",
    "if part2['eventOutcome_zscores'].equals( part2['eventOutcome_test_myzfunc']):\n",
    "    print('My Function Works! :)')\n",
    "else:\n",
    "    print('My Function Doesnt Work :(')\n",
    "# .equals() prints true so my fucntion works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 \n",
    "plot 'salaries' and 'NPS Score' on a subplot (1 row 2 columns) \n",
    "then repeat this for the zscores\n",
    "\n",
    "see image below for reference\n",
    "<img src=\"solutions/images/part2-plots.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot for raw salaries and NPS Score data goes here\n",
    "fig, (ax1, ax2) = plt.subplots(1,2,figsize=(19,8))\n",
    "\n",
    "ax1.hist(part2['salaries'])\n",
    "ax1.set_title('Salaries')\n",
    "ax1.set(xlabel = 'Salaries')\n",
    "\n",
    "ax2.hist(part2['NPS Score'])\n",
    "ax2.set_title('NPS Score')\n",
    "ax2.set(xlabel = 'NPS Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot for zscores for salaries and NPS Score data goes here\n",
    "fig, (ax1, ax2) = plt.subplots(1,2,figsize=(19,8))\n",
    "\n",
    "ax1.hist(part2['salaries_zscores'])\n",
    "ax1.set_title('Salaries')\n",
    "ax1.set(xlabel = 'Salaries Z-Scores')\n",
    "\n",
    "ax2.hist(part2['NPS Score_zscores'])\n",
    "ax2.set_title('NPS Score')\n",
    "ax2.set(xlabel = 'NPS Score Z-Scores')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4 - PMF\n",
    "using the column 'eventOutcomes'\n",
    "\n",
    "create a PMF and plot the PMF as a bar chart\n",
    "\n",
    "See image below for referenc\n",
    "\n",
    "<img src=\"solutions/images/part4_pmf.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "freq = {}\n",
    "for outcome in part2['eventOutcome']: #count the frequency of the event outcome\n",
    "    if (outcome in freq):\n",
    "        freq[outcome] += 1\n",
    "    else:\n",
    "        freq[outcome] = 0\n",
    "\n",
    "total_outcomes = sum(freq.values()) #count the total outcomes in the sample\n",
    "\n",
    "for k,v in freq.items():\n",
    "    freq[k] = v/total_outcomes #divide the counts by the total number of samples to get probability\n",
    "freq.values()\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.bar(freq.keys(), freq.values())\n",
    "plt.title('Event Outcome PMF')\n",
    "plt.ylabel('Probability')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5 - CDF\n",
    "plot the CDF of Event Outcomes as a scatter plot using the information above\n",
    "\n",
    "See image below for reference \n",
    "\n",
    "<img src=\"solutions/images/part5_cmf.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_array = np.array(list(freq.values()))\n",
    "\n",
    "cdf_array = np.cumsum(prob_array) #use cum sum to build array for cdf last value must equal 1\n",
    "\n",
    "cdf_dict = {}\n",
    "for k,v in freq.items(): # create a new dictionary with the event outcomes and their cdf values\n",
    "    cdf_dict[k] = cdf_array[k] \n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(cdf_dict.keys(),cdf_dict.values())\n",
    "plt.title('Cumulative Mass Function for Event Outcome')\n",
    "plt.ylabel('P(E<=N)')\n",
    "plt.xlabel('Event Outcome')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus:\n",
    "* using np.where find salaries with zscores <= -2.0\n",
    "\n",
    "* calculate the skewness and kurtosis for the NPS Score column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find salaries with zscores <= 2.0 \n",
    "np.where(part2['salaries_zscores'] <= 2.0) #not sure what else I am supposed to do with this?\n",
    "\n",
    "salary_zscores_lessthanorequal_2 = part2['salaries_zscores'].iloc[np.where(part2['salaries_zscores'] <= 2.0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate skewness and kurtosis of NPS Score column\n",
    "def get_skewness(data): #\n",
    "    x_bar = data.mean()\n",
    "    sigma = data.std()\n",
    "    skew_lst = []\n",
    "    for point in data:\n",
    "        skew = ((point - x_bar)**3) / (sigma**3)\n",
    "        skew_lst.append(skew)\n",
    "    skew_lst = np.array(skew_lst)\n",
    "    return skew_lst\n",
    "\n",
    "part2['NPS_skewness'] = get_skewness(part2['NPS Score']) #very similar to z score function except cubed\n",
    "part2.head()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kurtosis(data):\n",
    "    x_bar = data.mean()\n",
    "    sigma = data.std()\n",
    "    kurt_lst = []\n",
    "    for point in data:\n",
    "        kurt = ((point - x_bar)**4) / (sigma**4)\n",
    "        kurt_lst.append(kurt)\n",
    "    kurt_lst = np.array(kurt_lst)\n",
    "    return kurt_lst\n",
    "\n",
    "part2['NPS_kurtosis'] = get_kurtosis(part2['NPS Score']) #very similar to z score function except quartic\n",
    "part2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run the cell below to convert your notebook to a README for assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbconvert --to markdown assessment.ipynb && mv assessment.md README.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
